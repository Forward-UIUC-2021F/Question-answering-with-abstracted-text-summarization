TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.Build and train ML models easily using intuitive high-level APIs like Keras with eager execution, which makes for immediate model iteration and easy debugging.Easily train and deploy models in the cloud, on-prem, in the browser, or on-device no matter what language you use.A simple and flexible architecture to take new ideas from concept to code, to state-of-the-art models, and to publication faster.Simple step-by-step walkthroughs to solve common ML problems with TensorFlow.Train a neural network to classify images of clothing, like sneakers and shirts, in this fast-paced overview of a complete TensorFlow program.Start with building and training a retrieval model to predict a set of movies that a user is likely to watch, and then use a ranking model to create recommendations.Train a generative adversarial network to generate images of handwritten digits, using the Keras Subclassing API.A diverse community of developers, enterprises and researchers are using ML to solve challenging, real-world problems. Learn how their research and applications are being #PoweredbyTF and how you can share your story.Check out the TensorFlow blog for additional updates, and subscribe to our monthly TensorFlow newsletter to get the latest announcements sent directly to your inbox.Dev Library is a showcase of what developers have created with Google technologies. See what’s being built with ML, and submit your own!Developers and enthusiasts from around the world came together to share the latest in TensorFlow. Watch our collection of TensorFlow keynotes, sessions, workshops, AMAs, and more.Discover solutions to help you integrate machine learning in your mobile and web apps, and new Google Developers learning pathways to guide you through common ML scenarios and custom use cases.Explore our new discussion platform to share ideas, find answers to technical questions, and learn the latest from members of the community and the TensorFlow team. Create an account and join the conversation!We are committed to fostering an open and welcoming ML community. Join the TensorFlow community and help grow the ecosystem.Join the TensorFlow Forum to share ideas, discuss technical questions and connect with the TensorFlow community.We post regularly to the TensorFlow Blog, with content from the TensorFlow team and the best articles from the community.Our YouTube Channel focuses on machine learning and AI with TensorFlow. Explore a number of new shows, including TensorFlow Meets, Ask TensorFlow, and Coding TensorFlow.For up-to-date news and updates from the community and the TensorFlow team, follow @tensorflow on Twitter.Join the TensorFlow announcement mailing list to learn about the latest release updates, security advisories, and other important information from the TensorFlow team.######
TensorFlow makes it easy for beginners and experts to create machine learning models for desktop, mobile, web, and cloud. See the sections below to get started.Learn the foundation of TensorFlow with tutorials for beginners and experts to help you create your next machine learning project.Use TensorFlow.js to create new machine learning models and deploy existing models with JavaScript.Run inference with TensorFlow Lite on mobile and embedded devices like Android, iOS, Edge TPU, and Raspberry Pi.Deploy a production-ready ML pipeline for training and inference using TensorFlow Extended (TFX).TensorFlow provides a collection of workflows to develop and train models using Python or JavaScript, and to easily deploy in the cloud, on-prem, in the browser, or on-device no matter what language you use.TensorFlow is easier to use with a basic understanding of machine learning principles and core concepts. Learn and apply fundamental machine learning practices to develop your skills.Begin with curated curriculums to improve your skills in foundational ML areas.######
Whether you're an expert or a beginner, TensorFlow is an end-to-end platform that makes it easy for you to build and deploy ML models.TensorFlow offers multiple levels of abstraction so you can choose the right one for your needs. Build and train models by using the high-level Keras API, which makes getting started with TensorFlow and machine learning easy.If you need more flexibility, eager execution allows for immediate iteration and intuitive debugging. For large ML training tasks, use the Distribution Strategy API for distributed training on different hardware configurations without changing the model definition.TensorFlow has always provided a direct path to production. Whether it's on servers, edge devices, or the web, TensorFlow lets you train and deploy your model easily, no matter what language or platform you use.Use TensorFlow Extended (TFX) if you need a full production ML pipeline. For running inference on mobile and edge devices, use TensorFlow Lite. Train and deploy models in JavaScript environments using TensorFlow.js.Build and train state-of-the-art models without sacrificing speed or performance. TensorFlow gives you the flexibility and control with features like the Keras Functional API and Model Subclassing API for creation of complex topologies. For easy prototyping and fast debugging, use eager execution.TensorFlow also supports an ecosystem of powerful add-on libraries and models to experiment with, including Ragged Tensors, TensorFlow Probability, Tensor2Tensor and BERT.Did you ever want to know how a neural network works? Or what the steps are to solving an ML problem? Don't worry, we've got you covered. Below is a quick overview of the fundamentals of machine learning. Or, if you're looking for a more in-depth information, head to our education page for beginner and advanced content.Machine learning is the practice of helping software perform a task without explicit programming or rules. With traditional computer programming, a programmer specifies rules that the computer should use. ML requires a different mindset, though. Real-world ML focuses far more on data analysis than coding. Programmers provide a set of examples and the computer learns patterns from the data. You can think of machine learning as “programming with data”.There are multiple steps in the process of getting answers from data using ML. For a step-by-step overview, check out this guide that shows the complete workflow for text classification, and describes important steps like collecting a dataset, and training and evaluating a model with TensorFlow.A neural network is a type of model that can be trained to recognize patterns. It is composed of layers, including input and output layers, and at least one hidden layer. Neurons in each layer learn increasingly abstract representations of the data. For example, in this visual diagram we see neurons detecting lines, shapes, and textures. These representations (or learned features) make it possible to classify the data.Neural networks are trained by gradient descent. The weights in each layer begin with random values, and these are iteratively improved over time to make the network more accurate. A loss function is used to quantify how inaccurate the network is, and a procedure called backpropagation is used to determine whether each weight should be increased, or decreased, to reduce the loss.The TensorFlow community is an active group of developers, researchers, visionaries, tinkerers and problem solvers. The door is always open to contribute, collaborate and share your ideas.######
The following versions of the TensorFlow api-docs are currently available:Earlier branches of the documentation can be found on
GitHub.Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates. Some content is licensed under the numpy license.######
Tensors are the core datastructure of TensorFlow.js
      They are a generalization of vectors and matrices to potentially
      higher dimensions.We have utility functions for common cases like Scalar, 1D,
      2D, 3D and 4D tensors, as well a number of functions to initialize
      tensors in ways useful for machine learning.Creates a tf.Tensor with the provided values, shape and dtype.Creates rank-0 tf.Tensor (scalar) with the provided value and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.scalar() as it makes the code more readable.Creates rank-1 tf.Tensor with the provided values, shape and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.tensor1d() as it makes the code more readable.Creates rank-2 tf.Tensor with the provided values, shape and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.tensor2d() as it makes the code more readable.Creates rank-3 tf.Tensor with the provided values, shape and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.tensor3d() as it makes the code more readable.Creates rank-4 tf.Tensor with the provided values, shape and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.tensor4d() as it makes the code more readable.Creates rank-5 tf.Tensor with the provided values, shape and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.tensor5d() as it makes the code more readable.Creates rank-6 tf.Tensor with the provided values, shape and dtype.The same functionality can be achieved with tf.tensor(), but in general
we recommend using tf.tensor6d() as it makes the code more readable.Creates an empty tf.TensorBuffer with the specified shape and dtype.The values are stored in CPU as TypedArray. Fill the buffer using
buffer.set(), or by modifying directly buffer.values.When done, call buffer.toTensor() to get an immutable tf.Tensor with
those values.Creates a new tensor with the same values and shape as the specified
tensor.Converts two real numbers to a complex number.Given a tensor real representing the real part of a complex number, and a
tensor imag representing the imaginary part of a complex number, this
operation returns complex numbers elementwise of the form [r0, i0, r1, i1],
where r represents the real part and i represents the imag part.The input tensors real and imag must have the same shape.Returns a diagonal tensor with a given diagonal values.Given a diagonal, this operation returns a tensor with the diagonal and
everything else padded with zeros.Assume the input has dimensions [D1,..., Dk], then the output is a tensor
of rank 2k with dimensions [D1,..., Dk, D1,..., Dk]Creates a tf.Tensor filled with a scalar value.Returns the imaginary part of a complex (or real) tensor.Given a tensor input, this operation returns a tensor of type float that is
the imaginary part of each element in input considered as a complex number.
If input is real, a tensor of all zeros is returned.Return an evenly spaced sequence of numbers over the given interval.Creates a one-hot tf.Tensor. The locations represented by indices take
value onValue (defaults to 1), while all other locations take value
offValue (defaults to 0). If indices is rank R, the output has rank
R+1 with the last axis of size depth.Creates a tf.Tensor with all elements set to 1.Creates a tf.Tensor with all elements set to 1 with the same shape as the
given tensor.Prints information about the tf.Tensor including its data.Creates a new tf.Tensor1D filled with the numbers in the range provided.The tensor is a is half-open interval meaning it includes start, but
excludes stop. Decrementing ranges and negative step values are also
supported.svReturns the real part of a complex (or real) tensor.Given a tensor input, this operation returns a tensor of type float that is
the real part of each element in input considered as a complex number.If the input is real, it simply makes a clone.Creates a tf.Tensor with values sampled from a truncated normal
distribution.The generated values follow a normal distribution with specified mean and
standard deviation, except that values whose magnitude is more than 2
standard deviations from the mean are dropped and re-picked.Creates a new variable with the provided initial value.Creates a tf.Tensor with all elements set to 0.Creates a tf.Tensor with all elements set to 0 with the same shape as the
given tensor.
      This section shows the main Tensor related classes in TensorFlow.js and
      the methods we expose on them.
      A tf.Tensor object represents an immutable, multidimensional array of
numbers that has a shape and a data type.For performance reasons, functions that create tensors do not necessarily
perform a copy of the data passed to them (e.g. if the data is passed as a
Float32Array), and changes to the data will change the tensor. This is not
a feature and is not supported. To avoid this behavior, use the tensor before
changing the input data or create a copy with copy = tf.add(yourTensor, 0).See tf.tensor() for details on how to create a tf.Tensor.Returns a promise of tf.TensorBuffer that holds the underlying data.Returns a tf.TensorBuffer that holds the underlying data.Returns the tensor data as a nested array. The transfer of data is done
asynchronously.Returns the tensor data as a nested array. The transfer of data is done
synchronously.Asynchronously downloads the values from the tf.Tensor. Returns a
promise of TypedArray that resolves when the computation has finished.Synchronously downloads the values from the tf.Tensor. This blocks the
UI thread until the values are ready, which can cause performance issues.Prints the tf.Tensor. See tf.print() for details.Returns a copy of the tensor. See tf.clone() for details.Returns a human-readable description of the tensor. Useful for logging.A mutable tf.Tensor, useful for persisting state, e.g. for training.Assign a new tf.Tensor to this variable. The new tf.Tensor must have
the same shape and dtype as the old tf.Tensor.A mutable object, similar to tf.Tensor, that allows users to set values
at locations before converting to an immutable tf.Tensor.See tf.buffer() for creating a tensor buffer.Sets a value in the buffer at a given location.Returns the value in the buffer at the provided location.Creates an immutable tf.Tensor object from the buffer.This section describes some common Tensor
      transformations for reshaping and type-casting.This operation reshapes the "batch" dimension 0 into M + 1 dimensions of
shape blockShape + [batch], interleaves these blocks back into the grid
defined by the spatial dimensions [1, ..., M], to obtain a result with
the same rank as the input. The spatial dimensions of this intermediate
result are then optionally cropped according to crops to produce the
output. This is the reverse of tf.spaceToBatchND(). See below for a precise
description.This operation is equivalent to the following steps:Reshape x to reshaped of shape: [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape), x.shape[1], ..., x.shape[N-1]]Permute dimensions of reshapedto produce permuted of shape [batch / prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M], blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]Reshape permuted to produce reshapedPermuted of shape [batch / prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]Crop the start and end of dimensions [1, ..., M] of reshapedPermuted
              according to crops to produce the output of shape: [batch / prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1], ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] - crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]Return the shape of s0 op s1 with broadcast.compute r0, the broadcasted shape as a tensor.
s0, s1 and r0 are all integer vectors.This function returns the shape of the result of an operation between
two tensors of size s0 and s1 performed with broadcast.Broadcast an array to a compatible shape NumPy-style.The tensor's shape is compared to the broadcast shape from end to beginning.
Ones are prepended to the tensor's shape until is has the same length as
the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is
already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then
the input tensor is tiled N times along that axis (using tf.tile).Casts a tf.Tensor to a new dtype.Rearranges data from depth into blocks of spatial data. More specifically,
this op outputs a copy of the input tensor where values from the depth
dimension are moved in spatial blocks to the height and width dimensions.
The attr blockSize indicates the input block size and how the data is
moved.Chunks of data of size blockSize * blockSize from depth are rearranged
into non-overlapping blocks of size blockSize x blockSizeThe width the output tensor is inputWidth * blockSize, whereas the
height is inputHeight * blockSizeThe Y, X coordinates within each block of the output image are determined
by the high order component of the input channel indexThe depth of the input tensor must be divisible by blockSize * blockSizeThe dataFormat attr specifies the layout of the input and output tensors
with the following options: "NHWC": [ batch, height, width, channels ]
"NCHW": [ batch, channels, height, width ]Returns a tf.Tensor that has expanded rank, by inserting a dimension
into the tensor's shape.Pads a tf.Tensor using mirror padding.This operation implements the REFLECT and SYMMETRIC modes of pad.Pads a tf.Tensor with a given value and paddings.This operation implements CONSTANT mode. For REFLECT and SYMMETRIC,
refer to tf.mirrorPad()Also available are stricter rank-specific methods with the same signature
as this method that assert that paddings is of given length.Reshapes a tf.Tensor to a given shape.Given an input tensor, returns a new tensor with the same values as the
input tensor with shape shape.If one component of shape is the special value -1, the size of that
dimension is computed so that the total size remains constant. In
particular, a shape of [-1] flattens into 1-D. At most one component of
shape can be -1.If shape is 1-D or higher, then the operation returns a tensor with shape
shape filled with the values of tensor. In this case, the number of
elements implied by shape must be the same as the number of elements in
tensor.Computes the difference between two lists of numbers.Given a Tensor x and a Tensor y, this operation returns a Tensor out
that represents all values that are in x but not in y. The returned
Tensor out is sorted in the same order that the numbers appear in x
(duplicates are preserved). This operation also returns a Tensor indices that
represents the position of each out element in x. In other words:out[i] = x[idx[i]] for i in [0, 1, ..., out.length - 1]This operation divides "spatial" dimensions [1, ..., M] of the input into
a grid of blocks of shape blockShape, and interleaves these blocks with
the "batch" dimension (0) such that in the output, the spatial
dimensions [1, ..., M] correspond to the position within the grid,
and the batch dimension combines both the position within a spatial block
and the original batch position. Prior to division into blocks,
the spatial dimensions of the input are optionally zero padded
according to paddings. See below for a precise description.This operation is equivalent to the following steps:Zero-pad the start and end of dimensions [1, ..., M] of the input
              according to paddings to produce padded of shape paddedShape.Reshape padded to reshapedPadded of shape:
              [batch] + [paddedShape[1] / blockShape[0], blockShape[0], ..., paddedShape[M] / blockShape[M-1], blockShape[M-1]] + remainingShapePermute dimensions of reshapedPadded to produce permutedReshapedPadded
              of shape: blockShape + [batch] + [paddedShape[1] / blockShape[0], ..., paddedShape[M] / blockShape[M-1]] + remainingShapeReshape permutedReshapedPadded to flatten blockShape into the
              batch dimension, producing an output tensor of shape:
              [batch * prod(blockShape)] + [paddedShape[1] / blockShape[0], ..., paddedShape[M] / blockShape[M-1]] + remainingShapeRemoves dimensions of size 1 from the shape of a tf.Tensor.TensorFlow.js provides several operations
      to slice or extract parts of a tensor, or join multiple
      tensors together.
        Concatenates a list of tf.Tensors along a given axis.The tensors ranks and types must match, and their sizes must match in all
dimensions except axis.Also available are stricter rank-specific methods that assert that
tensors are of the given rank:Except tf.concat1d (which does not have axis param), all methods have
same signature as this method.Gather slices from tensor x's axis axis according to indices.Reverses a tf.Tensor along a specified axis.Also available are stricter rank-specific methods that assert that x is
of the given rank:Except tf.reverse1d (which does not have axis param), all methods have
same signature as this method.Extracts a slice from a tf.Tensor starting at coordinates begin
and is of size size.Also available are stricter rank-specific methods with the same signature
as this method that assert that x is of the given rank:Splits a tf.Tensor into sub tensors.If numOrSizeSplits is a number, splits x along dimension axis
into numOrSizeSplits smaller tensors.
Requires that numOrSizeSplits evenly divides x.shape[axis].If numOrSizeSplits is a number array, splits x into
numOrSizeSplits.length pieces. The shape of the i-th piece has the
same size as x except along dimension axis where the size is
numOrSizeSplits[i].Stacks a list of rank-R tf.Tensors into one rank-(R+1) tf.Tensor.Construct a tensor by repeating it the number of times given by reps.This operation creates a new tensor by replicating input reps
times. The output tensor's i'th dimension has input.shape[i] * reps[i] elements, and the values of input are replicated
reps[i] times along the i'th dimension. For example, tiling
[a, b, c, d] by [2] produces [a, b, c, d, a, b, c, d].Unstacks a tf.Tensor of rank-R into a list of rank-(R-1) tf.Tensors.Tensor contraction over specified indices and outer product.einsum allows defining Tensors by defining their element-wise computation.
This computation is based on
Einstein summation.This implementation of einsum has the following limitations:Creates a tf.Tensor with values drawn from a multinomial distribution.Creates a tf.Tensor with values sampled from a random number generator
function defined by the user.Creates a tf.Tensor with values sampled from a gamma distribution.Creates a tf.Tensor with values sampled from a normal distribution.Creates a tf.Tensor with values sampled from a uniform distribution.The generated values follow a uniform distribution in the range [minval,
maxval). The lower bound minval is included in the range, while the upper
bound maxval is excluded.Models are one of the primary abstractions used in
      TensorFlow.js Layers.  Models can be trained, evaluated, and used
      for prediction.  A model's state (topology, and optionally, trained
      weights) can be restored from various formats.Models are a collection of Layers, see Model Creation for
      details about how Layers can be connected.There are two primary ways of creating models.Creates a tf.Sequential model.  A sequential model is any model where the
outputs of one layer are the inputs to the next layer, i.e. the model
topology is a simple 'stack' of layers, with no branching or skipping.This means that the first layer passed to a tf.Sequential model should have
a defined input shape. What that means is that it should have received an
inputShape or batchInputShape argument, or for some type of layers
(recurrent, Dense...) an inputDim argument.The key difference between tf.model() and tf.sequential() is that
tf.sequential() is less generic, supporting only a linear stack of layers.
tf.model() is more generic and supports an arbitrary graph (without
cycles) of layers.It is also possible to specify a batch size (with potentially undetermined
batch dimension, denoted by "null") for the first layer using the
batchInputShape key. The following example is equivalent to the above:You can also use an Array of already-constructed Layers to create
a tf.Sequential model:A model is a data structure that consists of Layers and defines inputs
and outputs.The key difference between tf.model() and tf.sequential() is that
tf.model() is more generic, supporting an arbitrary graph (without
cycles) of layers. tf.sequential() is less generic and supports only a linear
stack of layers.When creating a tf.LayersModel, specify its input(s) and output(s). Layers
are used to wire input(s) to output(s).For example, the following code snippet defines a model consisting of
two dense layers, with 10 and 4 units, respectively.Used to instantiate an input to a model as a tf.SymbolicTensor.Users should call the input factory function for
consistency with other generator functions.Note: input is only necessary when using model. When using
sequential, specify inputShape for the first layer or use inputLayer
as the first layer.Load a graph model given a URL to the model definition.Example of loading MobileNetV2 from a URL and making a prediction with a
zeros input:Example of loading MobileNetV2 from a TF Hub URL and making a prediction with
a zeros input:For detailed information on the supported fields, see
              https://developer.mozilla.org/en-US/docs/Web/API/Request/RequestIf true, require that the provided weights exactly match those
              required by the layers. false means that both extra weights
              and missing weights will be silently ignored.For instance, if the path to the model JSON file is
              http://localhost/foo/model.json, then the default path prefix will be
              http://localhost/foo/. If a weight file has the path value
              group1-shard1of2 in the weight manifest, then the weight file will be
              loaded from http://localhost/foo/group1-shard1of2 by default. However,
              if you provide a weightPathPrefix value of
              http://localhost/foo/alt-weights, then the weight file will be loaded
              from the path http://localhost/foo/alt-weights/group1-shard1of2 instead.Setting this to true allows passing a TF-Hub module URL, omitting the
              standard model file name and the query parameters.With this func you can convert the weight file name to any URL.Load a model composed of Layer objects, including its topology and optionally
weights. See the Tutorial named "How to import a Keras Model" for usage
examples.This mode is not applicable to TensorFlow SavedModels or their converted
forms. For those models, use tf.loadGraphModel().Example 1. Load a model from an HTTP server.Example 2: Save model's topology and weights to browser local
storage;
then load it back.Example 3. Saving model's topology and weights to browser
IndexedDB;
then load it back.Example 4. Load a model from user-selected files from HTML
file input
elements.For detailed information on the supported fields, see
              https://developer.mozilla.org/en-US/docs/Web/API/Request/RequestIf true, require that the provided weights exactly match those
              required by the layers. false means that both extra weights
              and missing weights will be silently ignored.For instance, if the path to the model JSON file is
              http://localhost/foo/model.json, then the default path prefix will be
              http://localhost/foo/. If a weight file has the path value
              group1-shard1of2 in the weight manifest, then the weight file will be
              loaded from http://localhost/foo/group1-shard1of2 by default. However,
              if you provide a weightPathPrefix value of
              http://localhost/foo/alt-weights, then the weight file will be loaded
              from the path http://localhost/foo/alt-weights/group1-shard1of2 instead.Setting this to true allows passing a TF-Hub module URL, omitting the
              standard model file name and the query parameters.With this func you can convert the weight file name to any URL.Creates an IOHandler that triggers file downloads from the browser.The returned IOHandler instance can be used as model exporting methods such
as tf.Model.save and supports only saving.Creates an IOHandler that loads model artifacts from user-selected files.This method can be used for loading from files such as user-selected files
in the browser.
When used in conjunction with tf.loadLayersModel(), an instance of
tf.LayersModel (Keras-style) can be constructed from the loaded artifacts.Creates an IOHandler subtype that sends model artifacts to HTTP server.An HTTP request of the multipart/form-data mime type will be sent to the
path URL. The form data includes artifacts that represent the topology
and/or weights of the model. In the case of Keras-style tf.Model, two
blobs (files) exist in form-data:The following code snippet exemplifies the client-side code that uses this
function:If the default POST method is to be used, without any custom parameters
such as headers, you can simply pass an HTTP or HTTPS URL to model.save:The following GitHub Gist
https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864
implements a server based on flask that
can receive the request. Upon receiving the model artifacts via the requst,
this particular server reconsistutes instances of Keras
Models in memory.Copy a model from one URL to another.List all models stored in registered storage mediums.For a web browser environment, the registered mediums are Local Storage and
IndexedDB.Move a model from one URL to another.Remove a model specified by URL from a reigstered storage medium.Register a class with the serialization map of TensorFlow.js.This is often used for registering custom Layers, so they can be
serialized and deserialized.A tf.Functional is an alias to tf.LayersModel.A tf.GraphModel is a directed, acyclic graph built from a
SavedModel GraphDef and allows inference execution.A tf.GraphModel can only be created by loading from a model converted from
a TensorFlow SavedModel using
the command line converter tool and loaded via tf.loadGraphModel().Synchronously construct the in memory weight map and
compile the inference graph. Also initialize hashtable if any.Save the configuration and/or weights of the GraphModel.An IOHandler is an object that has a save method of the proper
signature defined. The save method manages the storing or
transmission of serialized data ("artifacts") that represent the
model's topology and weights onto or via a specific medium, such as
file downloads, local storage, IndexedDB in the web browser and HTTP
requests to a server. TensorFlow.js provides IOHandler
implementations for a number of frequently used saving mediums, such as
tf.io.browserDownloads() and tf.io.browserLocalStorage. See tf.io
for more details.This method also allows you to refer to certain types of IOHandlers
as URL-like string shortcuts, such as 'localstorage://' and
'indexeddb://'.Example 1: Save model's topology and weights to browser local
storage;
then load it back.Execute the inference for the input tensors.Executes inference for the model for given input tensors.Executes inference for the model for given input tensors in async
fashion, use this method when your model contains control flow ops.Releases the memory used by the weight tensors and resourceManager.A tf.LayersModel is a directed, acyclic graph of tf.Layers plus methods
for training, evaluation, prediction and saving.tf.LayersModel is the basic unit of training, inference and evaluation in
TensorFlow.js. To create a tf.LayersModel, use tf.LayersModel.Print a text summary of the model's layers.Configures and prepares the model for training and evaluation.  Compiling
outfits the model with an optimizer, loss, and/or metrics.  Calling fit
or evaluate on an un-compiled model will throw an error.Returns the loss value & metrics values for the model in test mode.Loss and metrics are specified during compile(), which needs to happen
before calls to evaluate().Evaluate model using a dataset object.Note: Unlike evaluate(), this method is asynchronous (async);Generates output predictions for the input samples.Note: the "step" mode of predict() is currently not supported.
This is because the TensorFlow.js core backend is imperative only.Returns predictions for a single batch of samples.Trains the model for a fixed number of epochs (iterations on a
dataset).Expected to be 0, 1, or 2. Default: 1.0 - No printed message during fit() call.
              1 - In Node.js (tfjs-node), prints the progress bar, together with
              real-time updates of loss and metric values and training speed.
              In the browser: no action. This is the default.
              2 - Not implemented yet.If the model has multiple outputs, a class weight can be specified for
              each of the outputs by setting this field an array of weight object
              or a object that maps model output names (e.g., model.outputNames[0])
              to weight objects.In the browser environment, yielding the main thread can improve the
              responsiveness of the page during training. In the Node.js environment,
              it can ensure tasks queued in the event loop can be handled in a timely
              manner.The value can be one of the following:Trains the model using a dataset object.Expected to be 0, 1, or 2. Default: 1.0 - No printed message during fit() call.
              1 - In Node.js (tfjs-node), prints the progress bar, together with
              real-time updates of loss and metric values and training speed.
              In the browser: no action. This is the default.
              2 - Not implemented yet.If validationData is an Array of Tensor objects, each tf.Tensor will be
              sliced into batches during validation, using the parameter
              validationBatchSize (which defaults to 32). The entirety of the
              tf.Tensor objects will be used in the validation.If validationData is a dataset object, and the validationBatches
              parameter is specified, the validation will use validationBatches batches
              drawn from the dataset object. If validationBatches parameter is not
              specified, the validation will stop when the dataset is exhausted.The model will not be trained on this data.Used only if validationData is an array of tf.Tensor objects, i.e., not
              a dataset object.If not specified, its value defaults to 32.Total number of batches of samples to draw from validationData for
              validation purpose before stopping at the end of every epoch. If not
              specified, evaluateDataset will use iterator.next().done as signal to
              stop validation.In the browser environment, yielding the main thread can improve the
              responsiveness of the page during training. In the Node.js environment,
              it can ensure tasks queued in the event loop can be handled in a timely
              manner.The value can be one of the following:If the model has multiple outputs, a class weight can be specified for
              each of the outputs by setting this field an array of weight object
              or a object that maps model output names (e.g., model.outputNames[0])
              to weight objects.Runs a single gradient update on a single batch of data.This method differs from fit() and fitDataset() in the following
regards:Save the configuration and/or weights of the LayersModel.An IOHandler is an object that has a save method of the proper
signature defined. The save method manages the storing or
transmission of serialized data ("artifacts") that represent the
model's topology and weights onto or via a specific medium, such as
file downloads, local storage, IndexedDB in the web browser and HTTP
requests to a server. TensorFlow.js provides IOHandler
implementations for a number of frequently used saving mediums, such as
tf.io.browserDownloads() and tf.io.browserLocalStorage. See tf.io
for more details.This method also allows you to refer to certain types of IOHandlers
as URL-like string shortcuts, such as 'localstorage://' and
'indexeddb://'.Example 1: Save model's topology and weights to browser local
storage;
then load it back.Example 2. Saving model's topology and weights to browser
IndexedDB;
then load it back.Example 3. Saving model's topology and weights as two files
(my-model-1.json and my-model-1.weights.bin) downloaded from
browser.Example 4. Send  model's topology and weights to an HTTP server.
See the documentation of tf.io.http() for more details
including specifying request parameters and implementation of the
server.Retrieves a layer based on either its name (unique) or index.Indices are based on order of horizontal graph traversal (bottom-up).If both name and index are specified, index takes precedence.A model with a stack of layers, feeding linearly from one to the next.tf.sequential() is a factory function that creates an instance of
tf.Sequential.Adds a layer instance on top of the layer stack.Print a text summary of the Sequential model's layers.Returns the loss value & metrics values for the model in test mode.Loss and metrics are specified during compile(), which needs to happen
before calls to evaluate().Evaluate model using a dataset object.Note: Unlike evaluate(), this method is asynchronous (async);Generates output predictions for the input samples.Note: the "step" mode of predict() is currently not supported.
This is because the TensorFlow.js core backend is imperative only.Trains the model for a fixed number of epochs (iterations on a dataset).Expected to be 0, 1, or 2. Default: 1.0 - No printed message during fit() call.
              1 - In Node.js (tfjs-node), prints the progress bar, together with
              real-time updates of loss and metric values and training speed.
              In the browser: no action. This is the default.
              2 - Not implemented yet.If the model has multiple outputs, a class weight can be specified for
              each of the outputs by setting this field an array of weight object
              or a object that maps model output names (e.g., model.outputNames[0])
              to weight objects.In the browser environment, yielding the main thread can improve the
              responsiveness of the page during training. In the Node.js environment,
              it can ensure tasks queued in the event loop can be handled in a timely
              manner.The value can be one of the following:Trains the model using a dataset object.The value field is expected to be an object of with fields
              xs and ys, which point to the feature tensor and the target tensor,
              respectively. This case is for models with exactly one input and one
              output (e.g.. a sequential model). For example:If the model has multiple inputs, the xs field of value should
              be an object mapping input names to their respective feature tensors.
              For example:If the model has multiple outputs, the ys field of value should
              be an object mapping output names to their respective target tensors.
              For example:Expected to be 0, 1, or 2. Default: 1.0 - No printed message during fit() call.
              1 - In Node.js (tfjs-node), prints the progress bar, together with
              real-time updates of loss and metric values and training speed.
              In the browser: no action. This is the default.
              2 - Not implemented yet.If validationData is an Array of Tensor objects, each tf.Tensor will be
              sliced into batches during validation, using the parameter
              validationBatchSize (which defaults to 32). The entirety of the
              tf.Tensor objects will be used in the validation.If validationData is a dataset object, and the validationBatches
              parameter is specified, the validation will use validationBatches batches
              drawn from the dataset object. If validationBatches parameter is not
              specified, the validation will stop when the dataset is exhausted.The model will not be trained on this data.Used only if validationData is an array of tf.Tensor objects, i.e., not
              a dataset object.If not specified, its value defaults to 32.Total number of batches of samples to draw from validationData for
              validation purpose before stopping at the end of every epoch. If not
              specified, evaluateDataset will use iterator.next().done as signal to
              stop validation.In the browser environment, yielding the main thread can improve the
              responsiveness of the page during training. In the Node.js environment,
              it can ensure tasks queued in the event loop can be handled in a timely
              manner.The value can be one of the following:If the model has multiple outputs, a class weight can be specified for
              each of the outputs by setting this field an array of weight object
              or a object that maps model output names (e.g., model.outputNames[0])
              to weight objects.Runs a single gradient update on a single batch of data.This method differs from fit() and fitDataset() in the following
regards:tf.SymbolicTensor is a placeholder for a Tensor without any concrete value.They are most often encountered when building a graph of Layers for a
a tf.LayersModel and the input data's shape, but not values are known.Deregister the Op for graph model executor.Retrieve the OpMapper object for the registered op.Register an Op for graph model executor. This allow you to register
TensorFlow custom op or override existing op.Here is an example of registering a new MatMul Op.The inputs and attrs of the node object is based on the TensorFlow op
registry.Layers are the primary building block for 
      constructing a Model.  Each layer will typically perform some
      computation to transform its input to its output.Layers will automatically take care of creating and initializing
      the various internal variables/weights they need to function.It follows:
f(x) = alpha * (exp(x) - 1.) for x < 0,
f(x) = x for x >= 0.Input shape:
Arbitrary. Use the configuration inputShape when using this layer as the
first layer in a model.Output shape:
Same shape as the input.Leaky version of a rectified linear unit.It allows a small gradient when the unit is not active:
f(x) = alpha * x for x < 0.
f(x) = x for x >= 0.Input shape:
Arbitrary. Use the configuration inputShape when using this layer as the
first layer in a model.Output shape:
Same shape as the input.Parameterized version of a leaky rectified linear unit.It follows
f(x) = alpha * x for x < 0.
f(x) = x for x >= 0.
wherein alpha is a trainable weight.Input shape:
Arbitrary. Use the configuration inputShape when using this layer as the
first layer in a model.Output shape:
Same shape as the input.Input shape:
Arbitrary. Use the config field inputShape (Array of integers, does
not include the sample axis) when using this layer as the first layer
in a model.Output shape:
Same shape as the input.Input shape:
Arbitrary. Use the configuration inputShape when using this layer as the
first layer in a model.Output shape:
Same shape as the input.It follows:
f(x) = x for x > theta,
f(x) = 0 otherwise.Input shape:
Arbitrary. Use the configuration inputShape when using this layer as the
first layer in a model.Output shape:
Same shape as the input.Applies an activation function to an output.This layer applies element-wise activation function.  Other layers, notably
dense can also apply activation functions.  Use this isolated activation
function to extract the values before and after the
activation. For instance:Creates a dense (fully connected) layer.This layer implements the operation:
output = activation(dot(input, kernel) + bias)activation is the element-wise activation function
passed as the activation argument.kernel is a weights matrix created by the layer.bias is a bias vector created by the layer (only applicable if useBias
is true).nD tf.Tensor with shape: (batchSize, ..., inputDim).The most common situation would be
a 2D input with shape (batchSize, inputDim).nD tensor with shape: (batchSize, ..., units).For instance, for a 2D input with shape (batchSize, inputDim),
the output would have shape (batchSize, units).Note: if the input to the layer has a rank greater than 2, then it is
flattened prior to the initial dot product with the kernel.If unspecified, no activation is applied.Dropout consists in randomly setting a fraction rate of input units to 0 at
each update during training time, which helps prevent overfitting.For instance, if your inputs have shape (batchSize, timesteps, features)
              and you want the dropout mask to be the same for all timesteps, you can use
              noise_shape=(batch_size, 1, features).Maps positive integers (indices) into dense vectors of fixed size.
eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]Input shape:* 2D tensor with shape: [batchSize, sequenceLength].Output shape:* 3D tensor with shape: [batchSize, sequenceLength, outputDim].If this is True then all subsequent layers in the model need to support
              masking or an exception will be raised. If maskZero is set to True, as a
              consequence, index 0 cannot be used in the vocabulary (inputDim should
              equal size of vocabulary + 1).This argument is required if you are going to connect flatten then
              dense layers upstream (without it, the shape of the dense outputs cannot
              be computed).Flattens the input. Does not affect the batch size.A Flatten layer flattens each batch in its inputs to 1D (making the output
2D).Permutes the dimensions of the input according to a given pattern.Useful for, e.g., connecting RNNs and convnets together.Input shape:
Arbitrary. Use the configuration field inputShape when using this
layer as the first layer in a model.Output shape:
Same rank as the input shape, but with the dimensions re-ordered (i.e.,
permuted) according to the dims configuration of this layer.Repeats the input n times in a new dimension.Reshapes an input to a certain shape.Input shape:
Arbitrary, although all dimensions in the input shape must be fixed.
Use the configuration inputShape when using this layer as the
first layer in a model.Output shape:
[batchSize, targetShape[0], targetShape[1], ...,
targetShape[targetShape.length - 1]].This Layer type performs the same function as the Dropout layer, but it drops
entire 1D feature maps instead of individual elements. For example, if an
input example consists of 3 timesteps and the feature map for each timestep
has a size of 4, a spatialDropout1d layer may zero out the feature maps
of the 1st timesteps and 2nd timesteps completely while sparing all feature
elements of the 3rd timestep.If adjacent frames (timesteps) are strongly correlated (as is normally the
case in early convolution layers), regular dropout will not regularize the
activation and will otherwise just result in merely an effective learning
rate decrease. In this case, spatialDropout1d will help promote
independence among feature maps and should be used instead.Arguments:*
rate: A floating-point number >=0 and <=1. Fraction of the input elements
to drop.Input shape:*
3D tensor with shape (samples, timesteps, channels).Output shape:*
Same as the input shape.1D convolution layer (e.g., temporal convolution).This layer creates a convolution kernel that is convolved
with the layer input over a single spatial (or temporal) dimension
to produce a tensor of outputs.If use_bias is True, a bias vector is created and added to the outputs.If activation is not null, it is applied to the outputs as well.When using this layer as the first layer in a model, provide an
inputShape argument Array or null.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.If you don't specify the activation, none is applied.2D convolution layer (e.g. spatial convolution over images).This layer creates a convolution kernel that is convolved
with the layer input to produce a tensor of outputs.If useBias is True, a bias vector is created and added to the outputs.If activation is not null, it is applied to the outputs as well.When using this layer as the first layer in a model,
provide the keyword argument inputShape
(Array of integers, does not include the sample axis),
e.g. inputShape=[128, 128, 3] for 128x128 RGB pictures
in dataFormat='channelsLast'.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.If you don't specify the activation, none is applied.Transposed convolutional layer (sometimes called Deconvolution).The need for transposed convolutions generally arises
from the desire to use a transformation going in the opposite direction of
a normal convolution, i.e., from something that has the shape of the output
of some convolution to something that has the shape of its input while
maintaining a connectivity pattern that is compatible with said
convolution.When using this layer as the first layer in a model, provide the
configuration inputShape (Array of integers, does not include the
sample axis), e.g., inputShape: [128, 128, 3] for 128x128 RGB pictures in
dataFormat: 'channelsLast'.Input shape:
4D tensor with shape:
[batch, channels, rows, cols] if dataFormat is 'channelsFirst'.
or 4D tensor with shape
[batch, rows, cols, channels] if dataFormat is 'channelsLast.Output shape:
4D tensor with shape:
[batch, filters, newRows, newCols] if dataFormat is
'channelsFirst'. or 4D tensor with shape:
[batch, newRows, newCols, filters] if dataFormat is 'channelsLast'.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.If you don't specify the activation, none is applied.3D convolution layer (e.g. spatial convolution over volumes).This layer creates a convolution kernel that is convolved
with the layer input to produce a tensor of outputs.If useBias is True, a bias vector is created and added to the outputs.If activation is not null, it is applied to the outputs as well.When using this layer as the first layer in a model,
provide the keyword argument inputShape
(Array of integers, does not include the sample axis),
e.g. inputShape=[128, 128, 128, 1] for 128x128x128 grayscale volumes
in dataFormat='channelsLast'.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.If you don't specify the activation, none is applied.Cropping layer for 2D input (e.g., image).This layer can crop an input
at the top, bottom, left and right side of an image tensor.Input shape:
4D tensor with shape:channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape
              (batch, channels, ...)Depthwise Separable convolutions consists in performing just the first step
in a depthwise spatial convolution (which acts on each input channel
separately). The depthMultplier argument controls how many output channels
are generated per input channel in the depthwise step.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.If you don't specify the activation, none is applied.Separable convolution consists of first performing
a depthwise spatial convolution
(which acts on each input channel separately)
followed by a pointwise convolution which mixes together the resulting
output channels. The depthMultiplier argument controls how many
output channels are generated per input channel in the depthwise step.Intuitively, separable convolutions can be understood as
a way to factorize a convolution kernel into two smaller kernels,
or as an extreme version of an Inception block.Input shape:
4D tensor with shape:
[batch, channels, rows, cols] if data_format='channelsFirst'
or 4D tensor with shape:
[batch, rows, cols, channels] if data_format='channelsLast'.Output shape:
4D tensor with shape:
[batch, filters, newRows, newCols] if data_format='channelsFirst'
or 4D tensor with shape:
[batch, newRows, newCols, filters] if data_format='channelsLast'.
rows and cols values might have changed due to padding.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.If you don't specify the activation, none is applied.Repeats the rows and columns of the data
by size[0] and size[1] respectively.Input shape:
4D tensor with shape:
- If dataFormat is "channelsLast":
[batch, rows, cols, channels]
- If dataFormat is "channelsFirst":
[batch, channels, rows, cols]Output shape:
4D tensor with shape:
- If dataFormat is "channelsLast":
[batch, upsampledRows, upsampledCols, channels]
- If dataFormat is "channelsFirst":
[batch, channels, upsampledRows, upsampledCols]"channelsLast" corresponds to inputs with shape
              [batch, ..., channels]"channelsFirst" corresponds to inputs with shape [batch, channels, ...].Layer that performs element-wise addition on an Array of inputs.It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape). The inputs are specified as an
Array when the apply method of the Add layer instance is called. For
example:Layer that performs element-wise averaging on an Array of inputs.It takes as input a list of tensors, all of the same shape, and returns a
single tensor (also of the same shape). For example:Layer that concatenates an Array of inputs.It takes a list of tensors, all of the same shape except for the
concatenation axis, and returns a single tensor, the concatenation
of all inputs. For example:Layer that computes a dot product between samples in two tensors.E.g., if applied to a list of two tensors a and b both of shape
[batchSize, n], the output will be a tensor of shape [batchSize, 1],
where each entry at index [i, 0] will be the dot product between
a[i, :] and b[i, :].Integer or an Array of integers.If set to true, the output of the dot product isthe cosine
              proximity between the two samples.Layer that computes the element-wise maximum an Array of inputs.It takes as input a list of tensors, all of the same shape and returns a
single tensor (also of the same shape). For example:Layer that computes the element-wise minimum of an Array of inputs.It takes as input a list of tensors, all of the same shape and returns a
single tensor (also of the same shape). For example:Layer that multiplies (element-wise) an Array of inputs.It takes as input an Array of tensors, all of the same
shape, and returns a single tensor (also of the same shape).
For example:Batch normalization layer (Ioffe and Szegedy, 2014).Normalize the activations of the previous layer at each batch,
i.e. applies a transformation that maintains the mean activation
close to 0 and the activation standard deviation close to 1.Input shape:
Arbitrary. Use the keyword argument inputShape (Array of integers, does
not include the sample axis) when calling the constructor of this class,
if this layer is used as a first layer in a model.Output shape:
Same shape as input.For instance, after a Conv2D layer with data_format="channels_first",
              set axis=1 in batchNormalization.Layer-normalization layer (Ba et al., 2016).Normalizes the activations of the previous layer for each given example in a
batch independently, instead of across a batch like in batchNormalization.
In other words, this layer applies a transformation that maintanis the mean
activation within each example close to0 and activation variance close to 1.Input shape:
Arbitrary. Use the argument inputShape when using this layer as the first
layer in a model.Average pooling operation for spatial data.Average pooling operation for spatial data.For example, [2, 2] will halve the input in both spatial dimension.
              If only one integer is specified, the same window length
              will be used for both dimensions.Average pooling operation for 3D data.For example, [2, 2, 2] will halve the input in three dimensions.
              If only one integer is specified, the same window length
              will be used for all dimensions.Global average pooling operation for temporal data.Input Shape: 3D tensor with shape: [batchSize, steps, features].Output Shape:2D tensor with shape: [batchSize, features].Global average pooling operation for spatial data.Output shape:
2D tensor with shape: [batchSize, channels].The ordering of the dimensions in the inputs. CHANNEL_LAST corresponds
              to inputs with shape [batch, height, width, channels[ while
              CHANNEL_FIRST corresponds to inputs with shape
              [batch, channels, height, width].Global max pooling operation for temporal data.Input Shape: 3D tensor with shape: [batchSize, steps, features].Output Shape:2D tensor with shape: [batchSize, features].Global max pooling operation for spatial data.Output shape:
2D tensor with shape: [batchSize, channels].The ordering of the dimensions in the inputs. CHANNEL_LAST corresponds
              to inputs with shape [batch, height, width, channels[ while
              CHANNEL_FIRST corresponds to inputs with shape
              [batch, channels, height, width].Max pooling operation for temporal data.Max pooling operation for spatial data.For example, [2, 2] will halve the input in both spatial dimension.
              If only one integer is specified, the same window length
              will be used for both dimensions.Max pooling operation for 3D data.For example, [2, 2, 2] will halve the input in three dimensions.
              If only one integer is specified, the same window length
              will be used for all dimensions.Convolutional LSTM layer - Xingjian Shi 2015.This is an ConvRNN2D layer consisting of one ConvLSTM2DCell. However,
unlike the underlying ConvLSTM2DCell, the apply method of ConvLSTM2D
operates on a sequence of inputs. The shape of the input (not including the
first, batch dimension) needs to be 4-D, with the first dimension being time
steps. For example:If you pass null, no activation will be applied.If null, no activation is applied.Note: For superior performance, TensorFlow.js always uses implementation
              2, regardless of the actual value of this config field.You can set RNN layers to be "stateful", which means that the states
              computed for the samples in one batch will be reused as initial states
              for the samples in the next batch. This assumes a one-to-one mapping
              between samples in different successive batches.To reset the state of your model, call resetStates() on either the
              specific layer or on the entire model.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.ConvLSTM2DCell is distinct from the ConvRNN2D subclass ConvLSTM2D in
that its call method takes the input data of only a single time step and
returns the cell's output at the time step, while ConvLSTM2D takes the
input data over a number of time steps. For example:If null, no activation is applied.Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.Note: For superior performance, TensorFlow.js always uses implementation
              2, regardless of the actual value of this configuration field.Specifying any stride value != 1 is incompatible with specifying any
              dilationRate value != 1.channels_last corresponds to inputs with shape
              (batch, ..., channels)channels_first corresponds to inputs with shape (batch, channels, ...).Currently, specifying any dilationRate value != 1 is incompatible with
              specifying any strides value != 1.Gated Recurrent Unit - Cho et al. 2014.This is an RNN layer consisting of one GRUCell. However, unlike
the underlying GRUCell, the apply method of SimpleRNN operates
on a sequence of inputs. The shape of the input (not including the first,
batch dimension) needs to be at least 2-D, with the first dimension being
time steps. For example:If null, no activation is applied.Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.Note: For superior performance, TensorFlow.js always uses implementation
              2, regardless of the actual value of this configuration field.If you pass null, no activation will be applied.You can set RNN layers to be "stateful", which means that the states
              computed for the samples in one batch will be reused as initial states
              for the samples in the next batch. This assumes a one-to-one mapping
              between samples in different successive batches.To reset the state of your model, call resetStates() on either the
              specific layer or on the entire model.GRUCell is distinct from the RNN subclass GRU in that its
apply method takes the input data of only a single time step and returns
the cell's output at the time step, while GRU takes the input data
over a number of time steps. For example:Instance(s) of GRUCell can be used to construct RNN layers. The
most typical use of this workflow is to combine a number of cells into a
stacked RNN cell (i.e., StackedRNNCell internally) and use it to create an
RNN. For example:To create an RNN consisting of only one GRUCell, use the
tf.layers.gru().If null, no activation is applied.Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.Note: For superior performance, TensorFlow.js always uses implementation
              2, regardless of the actual value of this configuration field.Long-Short Term Memory layer - Hochreiter 1997.This is an RNN layer consisting of one LSTMCell. However, unlike
the underlying LSTMCell, the apply method of LSTM operates
on a sequence of inputs. The shape of the input (not including the first,
batch dimension) needs to be at least 2-D, with the first dimension being
time steps. For example:If null, no activation is applied.Note: For superior performance, TensorFlow.js always uses implementation
              2, regardless of the actual value of this config field.If you pass null, no activation will be applied.You can set RNN layers to be "stateful", which means that the states
              computed for the samples in one batch will be reused as initial states
              for the samples in the next batch. This assumes a one-to-one mapping
              between samples in different successive batches.To reset the state of your model, call resetStates() on either the
              specific layer or on the entire model.LSTMCell is distinct from the RNN subclass LSTM in that its
apply method takes the input data of only a single time step and returns
the cell's output at the time step, while LSTM takes the input data
over a number of time steps. For example:Instance(s) of LSTMCell can be used to construct RNN layers. The
most typical use of this workflow is to combine a number of cells into a
stacked RNN cell (i.e., StackedRNNCell internally) and use it to create an
RNN. For example:To create an RNN consisting of only one LSTMCell, use the
tf.layers.lstm().If null, no activation is applied.Mode 1 will structure its operations as a larger number of
              smaller dot products and additions.Mode 2 will batch them into fewer, larger operations. These modes will
              have different performance profiles on different hardware and
              for different applications.Note: For superior performance, TensorFlow.js always uses implementation
              2, regardless of the actual value of this configuration field.Input shape:
3D tensor with shape [batchSize, timeSteps, inputDim].Masking:
This layer supports masking for input data with a variable number
of timesteps. To introduce masks to your data,
use an embedding layer with the mask_zero parameter
set to True.Notes on using statefulness in RNNs:
You can set RNN layers to be 'stateful', which means that the states
computed for the samples in one batch will be reused as initial states
for the samples in the next batch. This assumes a one-to-one mapping
between samples in different successive batches.To enable statefulness:
- specify stateful: true in the layer constructor.
- specify a fixed batch size for your model, by passing
if sequential model:
batchInputShape=[...] to the first layer in your model.
else for functional model with 1 or more Input layers:
batchShape=[...] to all the first layers in your model.
This is the expected shape of your inputs including the batch size.
It should be a tuple of integers, e.g. (32, 10, 100).
- specify shuffle=False when calling fit().To reset the states of your model, call .resetStates() on either
a specific layer, or on your entire model.Note on specifying the initial state of RNNs
You can specify the initial state of RNN layers symbolically by
calling them with the option initialState. The value of
initialState should be a tensor or list of tensors representing
the initial state of the RNN layer.You can specify the initial state of RNN layers numerically by
calling resetStates with the keyword argument states. The value of
states should be a numpy array or list of numpy arrays representing
the initial state of the RNN layer.Note on passing external constants to RNNs
You can pass "external" constants to the cell using the constants
keyword argument of RNN.call method. This requires that the cell.call
method accepts the same keyword argument constants. Such constants
can be used to conditon the cell transformation on additional static inputs
(not changing over time), a.k.a an attention mechanism.You can set RNN layers to be "stateful", which means that the states
              computed for the samples in one batch will be reused as initial states
              for the samples in the next batch. This assumes a one-to-one mapping
              between samples in different successive batches.To reset the state of your model, call resetStates() on either the
              specific layer or on the entire model.Fully-connected RNN where the output is to be fed back to input.This is an RNN layer consisting of one SimpleRNNCell. However, unlike
the underlying SimpleRNNCell, the apply method of SimpleRNN operates
on a sequence of inputs. The shape of the input (not including the first,
batch dimension) needs to be at least 2-D, with the first dimension being
time steps. For example:If you pass null, no activation will be applied.You can set RNN layers to be "stateful", which means that the states
              computed for the samples in one batch will be reused as initial states
              for the samples in the next batch. This assumes a one-to-one mapping
              between samples in different successive batches.To reset the state of your model, call resetStates() on either the
              specific layer or on the entire model.SimpleRNNCell is distinct from the RNN subclass SimpleRNN in that its
apply method takes the input data of only a single time step and returns
the cell's output at the time step, while SimpleRNN takes the input data
over a number of time steps. For example:Instance(s) of SimpleRNNCell can be used to construct RNN layers. The
most typical use of this workflow is to combine a number of cells into a
stacked RNN cell (i.e., StackedRNNCell internally) and use it to create an
RNN. For example:To create an RNN consisting of only one SimpleRNNCell, use the
tf.layers.simpleRNN().Wrapper allowing a stack of RNN cells to behave as a single cell.Used to implement efficient stacked RNNs.If undefined (i.e., not provided), defaults to 'concat'.This wrapper applies a layer to every temporal slice of an input.The input should be at least 3D,  and the dimension of the index 1 will be
considered to be the temporal dimension.Consider a batch of 32 samples, where each sample is a sequence of 10 vectors
of 16 dimensions. The batch input shape of the layer is then [32, 10, 16], and the inputShape, not including the sample dimension, is
[10, 16].You can then use TimeDistributed to apply a Dense layer to each of the 10
timesteps, independently:The output will then have shape [32, 10, 32].TimeDistributed can be used with arbitrary layers, not just Dense, for
instance a Conv2D layer.A layer is a grouping of operations and weights that can be composed to
create a tf.LayersModel.Layers are constructed by using the functions under the
tf.layers namespace.Builds or executes a `Layer's logic.When called with tf.Tensor(s), execute the Layers computation and
return Tensor(s). For example:When called with tf.SymbolicTensor(s), this will prepare the layer for
future execution.  This entails internal book-keeping on shapes of
expected Tensors, wiring layers together, and initializing weights.Calling apply with tf.SymbolicTensors are typically used during the
building of non-tf.Sequential models. For example:Counts the total number of numbers (e.g., float32, int32) in the
weights.Must be implemented on all layers that have weights.Called when apply() is called to construct the weights.Returns the current values of the weights of the layer.Sets the weights of the layer, from Tensors.Adds a weight variable to the layer.The loss may potentionally be conditional on some inputs tensors,
for instance activity losses are conditional on the layer's inputs.Computes the output shape of the layer.Assumes that the layer will be built to match that input shape provided.Returns the config of the layer.A layer config is a TS dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.The config of a layer does not include connectivity
information, nor the layer class name.  These are handled
by 'Container' (one layer of abstraction above).Porting Note: The TS dictionary follows TS naming standrds for
keys, and uses tfjs-layers type-safe Enums.  Serialization methods
should use a helper function to convert to the pythonic storage
standard. (see serialization_utils.convertTsToPythonic)This method decrease the reference count of the Layer object by 1.A Layer is reference-counted. Its reference count is incremented by 1
the first item its apply() method is called and when it becomes a part
of a new Node (through calling the apply()) method on a
tf.SymbolicTensor).If the reference count of a Layer becomes 0, all the weights will be
disposed and the underlying memory (e.g., the textures allocated in WebGL)
will be freed.Note: If the reference count is greater than 0 after the decrement, the
weights of the Layer will not be disposed.After a Layer is disposed, it cannot be used in calls such as apply(),
getWeights() or setWeights() anymore.An input layer is an entry point into a tf.LayersModel.InputLayer is generated automatically for tf.Sequentialmodels by specifying theinputshapeorbatchInputShape` for the first layer.  It
should not be specified explicitly. However, it can be useful sometimes,
e.g., when constructing a sequential model from a subset of another
sequential model's layers. Like the code snippet below shows.Zero-padding layer for 2D input (e.g., image).This layer can add rows and columns of zeros
at the top, bottom, left and right side of an image tensor.Input shape:
4D tensor with shape:The ordering of the dimensions in the inputs.
              channelsLast corresponds to inputs with shape
              [batch, height, width, channels] while channelsFirst
              corresponds to inputs with shape
              [batch, channels, height, width].Applies Alpha Dropout to the input.As it is a regularization layer, it is only active at training time.Alpha Dropout is a Dropout that keeps mean and variance of inputs
to their original values, in order to ensure the self-normalizing property
even after this dropout.
Alpha Dropout fits well to Scaled Exponential Linear Units
by randomly setting activations to the negative saturation value.Input shape:
Arbitrary. Use the keyword argument inputShape
(tuple of integers, does not include the samples axis)
when using this layer as the first layer in a model.Output shape:
Same shape as input.As it is a regularization layer, it is only active at training time.Input shape:
Arbitrary. Use the keyword argument inputShape
(tuple of integers, does not include the samples axis)
when using this layer as the first layer in a model.Output shape:
Same shape as input.As it is a regularization layer, it is only active at training time.This is useful to mitigate overfitting
(you could see it as a form of random data augmentation).
Gaussian Noise (GS) is a natural choice as corruption process
for real valued inputs.Masks a sequence by using a mask value to skip timesteps.If all features for a given sample timestep are equal to mask_value,
then the sample timestep will be masked (skipped) in all downstream layers
(as long as they support masking).If any downstream layer does not support masking yet receives such
an input mask, an exception will be raised.Input shape:
Arbitrary. Use the keyword argument inputShape
(tuple of integers, does not include the samples axis)
when using this layer as the first layer in a model.Output shape:
Same shape as input.To perform mathematical computation on Tensors, we use
      operations. Tensors are immutable, so all operations always return
      new Tensors and never modify input Tensors.Adds two tf.Tensors element-wise, A + B. Supports broadcasting.Subtracts two tf.Tensors element-wise, A - B. Supports broadcasting.Multiplies two tf.Tensors element-wise, A * B. Supports broadcasting.We also expose tf.mulStrict which has the same signature as this op and
asserts that a and b are the same shape (does not broadcast).Divides two tf.Tensors element-wise, A / B. Supports broadcasting.Adds a list of tf.Tensors element-wise, each with the same shape and dtype.Divides two tf.Tensors element-wise, A / B. Supports broadcasting. Return 0
if denominator is 0.Divides two tf.Tensors element-wise, A / B. Supports broadcasting.
The result is rounded with floor function.Returns the max of a and b (a > b ? a : b) element-wise.
Supports broadcasting.We also expose tf.maximumStrict which has the same signature as this op and
asserts that a and b are the same shape (does not broadcast).Returns the min of a and b (a < b ? a : b) element-wise.
Supports broadcasting.We also expose minimumStrict which has the same signature as this op and
asserts that a and b are the same shape (does not broadcast).Returns the mod of a and b element-wise.
floor(x / y) * y + mod(x, y) = x
Supports broadcasting.We also expose tf.modStrict which has the same signature as this op and
asserts that a and b are the same shape (does not broadcast).Computes the power of one tf.Tensor to another. Supports broadcasting.Given a tf.Tensor x and a tf.Tensor y, this operation computes x^y for
corresponding elements in x and y. The result's dtype will be the upcasted
type of the base and exp dtypes.We also expose powStrict which has the same signature as this op and
asserts that base and exp are the same shape (does not broadcast).Returns (a - b) * (a - b) element-wise.
Supports broadcasting.Computes acos of the input tf.Tensor element-wise: acos(x)Computes the inverse hyperbolic cos of the input tf.Tensor element-wise:
acosh(x)Computes asin of the input tf.Tensor element-wise: asin(x)Computes inverse hyperbolic sin of the input tf.Tensor element-wise:
asinh(x)Computes atan of the input tf.Tensor element-wise: atan(x)Computes arctangent of tf.Tensors a / b element-wise: atan2(a, b).
Supports broadcasting.Computes inverse hyperbolic tan of the input tf.Tensor element-wise:
atanh(x)Computes ceiling of input tf.Tensor element-wise: ceil(x)Clips values element-wise. max(min(x, clipValueMax), clipValueMin)Computes cos of the input tf.Tensor element-wise: cos(x)Computes hyperbolic cos of the input tf.Tensor element-wise: cosh(x)Computes exponential linear element-wise: x > 0 ? x : (e ^ x) - 1.Computes gause error function of the input tf.Tensor element-wise:
erf(x)Computes exponential of the input tf.Tensor element-wise. e ^ xComputes exponential of the input tf.Tensor minus one element-wise.
e ^ x - 1Computes floor of input tf.Tensor element-wise: floor(x).Returns which elements of x are finite.Returns which elements of x are Infinity or -Infinity.RReturns which elements of x are NaN.Computes natural logarithm of the input tf.Tensor element-wise: ln(x)Computes natural logarithm of the input tf.Tensor plus one
element-wise: ln(1 + x)Computes log sigmoid of the input tf.Tensor element-wise:
logSigmoid(x). For numerical stability, we use -tf.softplus(-x).Computes leaky rectified linear element-wise with parametric alphas.x < 0 ? alpha * x : f(x) = xComputes reciprocal of x element-wise: 1 / xComputes rectified linear element-wise: max(x, 0).Computes rectified linear 6 element-wise: min(max(x, 0), 6).Computes round of input tf.Tensor element-wise: round(x).
It implements banker's rounding.Computes reciprocal of square root of the input tf.Tensor element-wise:
y = 1 / sqrt(x)x < 0 ? scale * alpha * (exp(x) - 1) : xComputes sigmoid element-wise, 1 / (1 + exp(-x))Returns an element-wise indication of the sign of a number.Computes sin of the input Tensor element-wise: sin(x)Computes hyperbolic sin of the input tf.Tensor element-wise: sinh(x)Computes softplus of the input tf.Tensor element-wise: log(exp(x) + 1)Computes square root of the input tf.Tensor element-wise: y = sqrt(x)Computes square of x element-wise: x ^ 2Computes step of the input tf.Tensor element-wise: x > 0 ? 1 : alpha * xComputes tan of the input tf.Tensor element-wise, tan(x)Computes hyperbolic tangent of the input tf.Tensor element-wise: tanh(x)Computes the dot product of two matrices and/or vectors, t1 and t2.Computes the dot product of two matrices, A * B. These must be matrices.Computes the norm of scalar, vectors, and matrices.
This function can compute several different vector norms (the 1-norm, the
Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)
and matrix norms (Frobenius, 1-norm, and inf-norm).Computes the outer product of two vectors, v1 and v2.Transposes the tf.Tensor. Permutes the dimensions according to perm.The returned tf.Tensor's dimension i will correspond to the input
dimension perm[i]. If perm is not given, it is set to [n-1...0],
where n is the rank of the input tf.Tensor. Hence by default, this
operation performs a regular matrix transpose on 2-D input tf.Tensors.Computes a 1D convolution over the input x.Computes a 2D convolution over the input x.Computes the transposed 2D convolution of an image, also known as a
deconvolution.Computes a 3D convolution over the input x.Computes the transposed 3D convolution of a volume, also known as a
deconvolution.Given a 4D input array and a filter array of shape
[filterHeight, filterWidth, inChannels, channelMultiplier] containing
inChannels convolutional filters of depth 1, this op applies a
different filter to each input channel (expanding from 1 channel to
channelMultiplier channels for each), then concatenates the results
together. The output has inChannels * channelMultiplier channels.Computes the grayscale dilation over the input x.Computes the 2D max pooling of an image with Argmax index.
The indices in argmax are flattened, so that a maximum value at position [b, y, x, c] becomes flattened index: (y * width + x) * channels + c if
include_batch_in_index is False; ((b * height + y) * width + x) * channels +c if include_batch_in_index is True.The indices returned are always in [0, height) x [0, width) before
flattening.Performs a depthwise convolution that acts separately on channels followed
by a pointwise convolution that mixes channels. Note that this is
separability between dimensions [1, 2] and 3, not spatial separability
between dimensions 1 and 2.Computes the logical and of elements across dimensions of a tf.Tensor.Reduces the input along the dimensions given in axes. Unless keepDims
is true, the rank of the tf.Tensor is reduced by 1 for each entry in
axes. If keepDims is true, the reduced dimensions are retained with
length 1. If axes has no entries, all dimensions are reduced, and an
tf.Tensor with a single element is returned.Computes the logical or of elements across dimensions of a tf.Tensor.Reduces the input along the dimensions given in axes. Unless keepDims
is true, the rank of the tf.Tensor is reduced by 1 for each entry in
axes. If keepDims is true, the reduced dimensions are retained with
length 1. If axes has no entries, all dimensions are reduced, and an
tf.Tensor with a single element is returned.Returns the indices of the maximum values along an axis.The result has the same shape as input with the dimension along axis
removed.Returns the indices of the minimum values along an axis.The result has the same shape as input with the dimension along axis
removed.Outputs a vector with length size and the same dtype as weights.If weights are empty, then index i stores the number of times the value
i is counted in x. If weights are non-empty, then index i stores the
sum of the value in weights at each index where the corresponding value in
x is i.Values in x outside of the range [0, size) are ignored.Outputs a vector with length size and the same dtype as weights.If weights are empty, then index i stores the number of times the value
i is counted in x. If weights are non-empty, then index i stores the
sum of the value in weights at each index where the corresponding value in
x is i.Values in x outside of the range [0, size) are ignored.Computes the log(sum(exp(elements across the reduction dimensions)).Reduces the input along the dimensions given in axis. Unless keepDims
is true, the rank of the array is reduced by 1 for each entry in axis.
If keepDims is true, the reduced dimensions are retained with length 1.
If axis has no entries, all dimensions are reduced, and an array with a
single element is returned.Computes the maximum of elements across dimensions of a tf.Tensor.Reduces the input along the dimensions given in axes. Unless keepDims
is true, the rank of the tf.Tensor is reduced by 1 for each entry in
axes. If keepDims is true, the reduced dimensions are retained with
length 1. If axes has no entries, all dimensions are reduced, and an
tf.Tensor with a single element is returned.Computes the mean of elements across dimensions of a tf.Tensor.Reduces x along the dimensions given in axis. Unless keepDims is
true, the rank of the tf.Tensor is reduced by 1 for each entry in axis.
If keepDims is true, the reduced dimensions are retained with length 1.
If axis has no entries, all dimensions are reduced, and a tf.Tensor with
a single element is returned.Computes the minimum value from the input.Reduces the input along the dimensions given in axes. Unless keepDims
is true, the rank of the array is reduced by 1 for each entry in axes.
If keepDims is true, the reduced dimensions are retained with length 1.
If axes has no entries, all dimensions are reduced, and an array with a
single element is returned.Computes the product of elements across dimensions of a tf.Tensor.Reduces the input along the dimensions given in axes. Unless keepDims
is true, the rank of the tf.Tensor is reduced by 1 for each entry in
axes. If keepDims is true, the reduced dimensions are retained with
length 1. If axes has no entries, all dimensions are reduced, and a
tf.Tensor with a single element is returned.Computes the sum of elements across dimensions of a tf.Tensor.Reduces the input along the dimensions given in axes. Unless keepDims
is true, the rank of the tf.Tensor is reduced by 1 for each entry in
axes. If keepDims is true, the reduced dimensions are retained with
length 1. If axes has no entries, all dimensions are reduced, and a
tf.Tensor with a single element is returned.Mean, variance, scale, and offset can be of two shapes:Also available are stricter rank-specific methods with the same signature
as this method that assert that parameters passed are of given rankNormalizes the activation of a local neighborhood across or within
channels.Calculates the mean and variance of x. The mean and variance are
calculated by aggregating the contents of x across axes. If x is
1-D and axes = [0] this is just the mean and variance of a vector.Computes the softmax normalized vector given the logits.Converts a sparse representation into a dense tensor.Builds an array dense with shape outputShape such that:// If sparseIndices is scalar
dense[i] = (i == sparseIndices ? sparseValues : defaultValue)// If sparseIndices is a vector, then for each i
dense[sparseIndices[i]] = sparseValues[i]// If sparseIndices is an n by d matrix, then for each i in [0, n)
dense[sparseIndices[i][0], ..., sparseIndices[i][d-1]] = sparseValues[i]
All other values in dense are set to defaultValue. If sparseValues is a
scalar, all sparse indices are set to this single value.If indices are repeated the final value is summed over all values for those
indices.Extracts crops from the input image tensor and resizes them using bilinear
sampling or nearest neighbor sampling (possibly with aspect ratio change)
to a common output size specified by cropSize.Flips the image left to right. Currently available in the CPU, WebGL, and
WASM backends.Converts images from grayscale to RGB format.Performs non maximum suppression of bounding boxes based on
iou (intersection over union).Performs non maximum suppression of bounding boxes based on
iou (intersection over union).This is the async version of nonMaxSuppressionAsynchronously performs non maximum suppression of bounding boxes based on
iou (intersection over union), with an option to pad results.Asynchronously performs non maximum suppression of bounding boxes based on
iou (intersection over union), with an option to pad results.Performs non maximum suppression of bounding boxes based on
iou (intersection over union).This op also supports a Soft-NMS mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes, therefore favoring different regions of the image
with high scores. To enable this Soft-NMS mode, set the softNmsSigma
parameter to be larger than 0.Asynchronously performs non maximum suppression of bounding boxes based on
iou (intersection over union).This op also supports a Soft-NMS mode (c.f.
Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
of other overlapping boxes, therefore favoring different regions of the image
with high scores. To enable this Soft-NMS mode, set the softNmsSigma
parameter to be larger than 0.Bilinear resize a single 3D image or a batch of 3D images to a new shape.NearestNeighbor resize a batch of 3D images to a new shape.Rotates the input image tensor counter-clockwise with an optional offset
center of rotation. Currently available in the CPU, WebGL, and WASM backends.Applies the given transform(s) to the image(s).Computes the next state and output of a BasicLSTMCell.Computes the next states and outputs of a stack of LSTMCells.Each cell output is used as input to the next cell.Returns the truth value of (a == b) element-wise. Supports broadcasting.Returns the truth value of (a > b) element-wise. Supports broadcasting.Returns the truth value of (a >= b) element-wise. Supports broadcasting.Returns the truth value of (a < b) element-wise. Supports broadcasting.Returns the truth value of (a <= b) element-wise. Supports broadcasting.Returns the truth value of a AND b element-wise. Supports broadcasting.Returns the truth value of NOT x element-wise.Returns the truth value of a OR b element-wise. Supports broadcasting.Returns the truth value of a XOR b element-wise. Supports broadcasting.Returns the truth value of (a != b) element-wise. Supports broadcasting.Returns the elements, either a or b depending on the condition.If the condition is true, select from a, otherwise select from b.Returns the coordinates of true elements of condition.The coordinates are returned in a 2-D tensor where the first dimension (rows)
represents the number of true elements, and the second dimension (columns)
represents the coordinates of the true elements. Keep in mind, the shape of
the output tensor can vary depending on how many true values there are in
input. Indices are output in row-major order. The resulting tensor has the
shape [numTrueElems, condition.rank].This is analogous to calling the python tf.where(cond) without an x or y.Computes the confusion matrix from true labels and predicted labels.Returns whether the targets are in the top K predictions.Finds the values and indices of the k largest entries along the last
dimension.If the input is a vector (rank=1), finds the k largest entries in the vector
and outputs their values and indices as vectors. Thus values[j] is the j-th
largest entry in input, and its index is indices[j].
For higher rank inputs, computes the top k entries along the last dimension.If two elements are equal, the lower-index element appears first.Finds unique elements along an axis of a tensor.It returns a tensor values containing all of the unique elements along the
axis of the given tensor x in the same order that they occur along the
axis in x; x does not need to be sorted. It also returns a tensor
indices the same size as the number of the elements in x along the axis
dimension. It contains the index in the unique output values.Computes the cumulative sum of a tf.Tensor along axis.Gather slices from input tensor into a Tensor with shape specified by
indices.indices is an K-dimensional integer tensor, best thought of as a
(K-1)-dimensional tensor of indices into input, where each element defines a
slice of input:
output[\(i_0, ..., i_{K-2}\)] = input[indices[\(i_0, ..., i_{K-2}\)]]Whereas in tf.gather(), indices defines slices into the first dimension of
input, in tf.gatherND(), indices defines slices into the first N dimensions
of input, where N = indices.shape[-1].The last dimension of indices can be at most the rank of input:
indices.shape[-1] <= input.rankThe last dimension of indices corresponds to elements
(if indices.shape[-1] == input.rank) or slices
(if indices.shape[-1] < input.rank) along dimension indices.shape[-1] of
input.
The output tensor has shape
indices.shape[:-1] + input.shape[indices.shape[-1]:]Note that on CPU, if an out of bound index is found, an error is returned. On
GPU, if an out of bound index is found, a 0 is stored in the corresponding
output value.Broadcasts parameters for evaluation on an N-D grid.Given N one-dimensional coordinate arrays *args, returns a list outputs
of N-D coordinate arrays for evaluating expressions on an N-D grid.Notes:
meshgrid supports cartesian ('xy') and matrix ('ij') indexing conventions.
When the indexing argument is set to 'xy' (the default), the broadcasting
instructions for the first two dimensions are swapped.
Examples:
Calling const [X, Y] = meshgrid(x, y) with the tensorsCreates a new tensor by applying sparse updates to individual
values or slices within a zero tensor of the given shape tensor according to
indices. This operator is the inverse of the tf.gatherND() operator which
extracts values or slices from a given tensor.Extracts a strided slice of a tensor.Roughly speaking, this op extracts a slice of size (end-begin)/stride from
the given input tensor (x). Starting at the location specified by begin the
slice continues by adding stride to the index until all dimensions are not
less than end. Note that a stride can be negative, which causes a reverse
slice.Computes the 1-dimensional discrete Fourier transform over the inner-most
dimension of input.Computes the inverse 1-dimensional discrete Fourier transform over the
inner-most dimension of input.Inversed real value input fast Fourier transform.Computes the 1-dimensional inversed discrete Fourier transform over the
inner-most dimension of the real input.Real value input fast Fourier transform.Computes the 1-dimensional discrete Fourier transform over the
inner-most dimension of the real input.Computes the sum along segments of a tf.Tensor.Compute the moving average of a variable.Without zeroDebias, the moving average operation is defined by:
v += delta
where
delta = (1 - decay) * (x - v)With zeroDebias (default), the delta term is scaled to debias the
effect of the (assumed) zero-initialization of v.
delta /= (1 - decay ^ step)For more details on the zero-debiasing algorithm, see:
https://arxiv.org/abs/1412.6980Note that this function is completely stateless and does not keep track of
step count. The step count needs to be maintained by the caller and passed
in as step.Expands input into frames of frameLength.
Slides a window size with frameStep.Computes the Short-time Fourier Transform of signals
See: https://en.wikipedia.org/wiki/Short-time_Fourier_transformCopy a tensor setting everything outside a central band in each innermost
matrix to zero.The band part is computed as follows: Assume input has k dimensions
[I, J, K, ..., M, N], then the output is a tensor with the same shape where
band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n].
The indicator function
in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower))
&& (num_upper < 0 || (n-m) <= num_upper)Compute QR decomposition of m-by-n matrix using Householder transformation.The input SparseTensor is represented via the map of inputs {indices,
values, denseShape}. The output SparseTensor has the same denseShape
but with indices outputIndices and values outputValues. This op inserts a
single entry for every row that doesn't have any values. The index is created
as [row, 0, ..., 0] and the inserted value is defaultValue.For example, suppose spInput has shape [5, 6] and non-empty values:
[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: dRows 1 and 4 are empty, so the output will be of shape [5, 6] with values:
[0, 1]: a
[0, 3]: b
[1, 0]: defaultValue
[2, 0]: c
[3, 1]: d
[4, 0]: defaultValueThe output SparseTensor will be in row-major order and will have the same
shape as the input.This op also returns an indicator vector shaped [dense_shape[0]] such that
emptyRowIndicator[i] = True iff row i was an empty row.And a reverse index map vector shaped [indices.shape[0]] that is used during
backpropagation, reverseIndexMap[i] = outi s.t. indices[i, j] ==
outputIndices[outi, j] for all jThis operation has the same semantics as reshape on the represented dense
tensor. The inputIndices are recomputed based on the requested newShape.
If one component of newShape is the special value -1, the size of that
dimension is computed so that the total dense size remains constant. At most
one component of newShape can be -1. The number of dense elements implied
by newShape must be the same as the number of dense elements originally
implied by inputShape. Reshaping does not affect the order of values in the
SparseTensor. If the input tensor has rank R_in and N non-empty values, and
newShape has length R_out, then inputIndices has shape [N, R_in],
inputShape has length R_in, outputIndices has shape [N, R_out], and
outputShape has length R_out.Computes the mean along sparse segments of a tensor.Computes the sum along sparse segments of a tensor.Creates ngrams from ragged string data.This op accepts a ragged tensor with 1 ragged dimension containing only
strings and outputs a ragged tensor with 1 ragged dimension containing ngrams
of that string, joined along the innermost axis.Split elements of input based on delimiter into a SparseTensor .Let N be the size of source (typically N will be the batch size). Split each
element of input based on delimiter and return a SparseTensor containing
the splitted tokens. Empty tokens are ignored if skipEmpty is set to True.delimiter can be empty, or a string of split characters. If delimiter is
an empty string, each element of input is split into individual
character strings. Otherwise every character of delimiter is a potential
split point.Converts each string in the input Tensor to its hash mod by a number of
buckets.The hash function is deterministic on the content of the string within the
process and will never change. However, it is not suitable for cryptography.
This function may be used when CPU time is scarce and inputs are trusted or
unimportant. There is a risk of adversaries constructing inputs that all hash
to the same bucket.We also provide an API to do perform training, and
      compute gradients. We compute gradients eagerly, users provide a function
      that is a combination of operations and we automatically differentiate
      that function's output with respect to its inputs.
      For those familiar with TensorFlow, the API we expose exactly mirrors
      the TensorFlow Eager API.
      Provided f(x), returns another function g(x, dy?), which gives the
gradient of f(x) with respect to x.If dy is provided, the gradient of f(x).mul(dy).sum() with respect to
x is computed instead. f(x) must take a single tensor x and return a
single tensor y. If f() takes multiple inputs, use tf.grads() instead.Provided f(x1, x2,...), returns another function g([x1, x2,...], dy?),
which gives an array of gradients of f() with respect to each input
[x1,x2,...].If dy is passed when calling g(), the gradient of
f(x1,...).mul(dy).sum() with respect to each input is computed instead.
The provided f must take one or more tensors and return a single tensor
y. If f() takes a single input, we recommend using tf.grad() instead.Overrides the gradient computation of a function f.Takes a function
f(...inputs, save) => {value: Tensor, gradFunc: (dy, saved) => Tensor[]}
and returns another function g(...inputs) which takes the same inputs as
f. When called, g returns f().value. In backward mode, custom gradients
with respect to each input of f are computed using f().gradFunc.The save function passsed to f should be used for saving tensors needed
in the gradient. And the saved passed to the gradFunc is a
NamedTensorMap, which contains those saved tensor.Like tf.grad(), but also returns the value of f(). Useful when f()
returns a metric you want to show.The result is a rich object with the following properties:Like tf.grads(), but returns also the value of f(). Useful when f()
returns a metric you want to show.The result is a rich object with the following properties:Computes and returns the gradient of f(x) with respect to the list of
trainable variables provided by varList. If no list is provided, it
defaults to all trainable variables.Constructs a tf.SGDOptimizer that uses stochastic gradient descent.Constructs a tf.MomentumOptimizer that uses momentum gradient
descent.Constructs a tf.AdagradOptimizer that uses the Adagrad algorithm.
See
http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf
or
http://ruder.io/optimizing-gradient-descent/index.html#adagradConstructs a tf.AdadeltaOptimizer that uses the Adadelta algorithm.
See https://arxiv.org/abs/1212.5701Constructs a tf.AdamOptimizer that uses the Adam algorithm.
See https://arxiv.org/abs/1412.6980Constructs a tf.AdamaxOptimizer that uses the Adamax algorithm.
See https://arxiv.org/abs/1412.6980Constructs a tf.RMSPropOptimizer that uses RMSProp gradient
descent. This implementation uses plain momentum and is not centered
version of RMSProp.Computes the absolute difference loss between two tensors.Computes the weighted loss between two tensors.Computes the cosine distance loss between two tensors.Computes the Hinge loss between two tensors.Computes the huber loss between two tensors.Computes the log loss between two tensors.Computes the mean squared error between two tensors.Computes the sigmoid cross entropy loss between two tensors.If labelSmoothing is nonzero, smooth the labels towards 1/2:newMulticlassLabels = multiclassLabels * (1 - labelSmoothing)
+ 0.5 * labelSmoothingComputes the softmax cross entropy loss between two tensors.If labelSmoothing is nonzero, smooth the labels towards 1/2:newOnehotLabels = onehotLabels * (1 - labelSmoothing)
+ labelSmoothing / numClassesExecutes f() and minimizes the scalar output of f() by computing
gradients of y with respect to the list of trainable variables provided by
varList. If no list is provided, it defaults to all trainable variables.Executes f() and computes the gradient of the scalar output of f() with
respect to the list of trainable variables provided by varList. If no
list is provided, it defaults to all trainable variables.Updates variables by using the computed gradients.Executes the provided function fn and after it is executed, cleans up all
intermediate tensors allocated by fn except those returned by fn.
fn must not return a Promise (async functions not allowed). The returned
result can be a complex object.Using this method helps avoid memory leaks. In general, wrap calls to
operations in tf.tidy() for automatic memory cleanup.NOTE: Variables do not get cleaned up when inside a tidy(). If you want to
dispose variables, please use tf.disposeVariables() or call dispose()
directly on variables.Disposes any tf.Tensors found within the provided object.Keeps a tf.Tensor generated inside a tf.tidy() from being disposed
automatically.Returns memory info at the current time in the program. The result is an
object with the following properties:Executes f() and returns a promise that resolves with timing
information.The result is an object with the following properties:Returns a promise that resolve when a requestAnimationFrame has completed.On Node.js this uses setImmediate instead of requestAnimationFrame.This is simply a sugar method so that users can do the following:
await tf.nextFrame();Executes the provided function f() and returns a promise that resolves
with information about the function's memory use:TensorFlow.js can run mathematical operations on
      different backends. Currently, we support WebGL and JavaScript
      CPU. By default, we choose the 'best' backend available, but
      allow users to customize their backend.The environment contains evaluated flags as well as the registered platform.
This is always used as a global singleton and can be retrieved with
tf.env().Dispose all variables kept in backend engine.Enables debug mode which will log information about all executed kernels:
the elapsed time of the kernel execution, as well as the rank, shape, and
size of the output tensor.Debug mode will significantly slow down your application as it will
download the result of every operation to the CPU. This should not be used in
production. Debug mode does not affect the timing information of the kernel
execution as we do not measure download time in the kernel execution time.Enables production mode which disables correctness checks in favor of
performance.It returns the global engine that keeps track of all tensors and backends.Returns the current environment (a global singleton).The environment object contains the evaluated feature values as well as the
active platform.Constraints are added to attributes
      of a Layer (such as weights, kernels, or biases) at
      construction time to clamp, or otherwise enforce an allowed range,
      of values for different components of the Layer.Base class for functions that impose constraints on weight valuesConstrains the weights incident to each hidden unit
to have a norm less than or equal to a desired value.References
- Dropout: A Simple Way to Prevent Neural Networks from Overfitting
Srivastava, Hinton, et al.
2014For instance, in a Dense layer the weight matrix
              has shape [inputDim, outputDim],
              set axis to 0 to constrain each weight vector
              of length [inputDim,].
              In a Conv2D layer with dataFormat="channels_last",
              the weight tensor has shape
              [rows, cols, inputDepth, outputDepth],
              set axis to [0, 1, 2]
              to constrain the weights of each filter tensor of size
              [rows, cols, inputDepth].Constains the weight to be non-negative.Constrains the weights incident to each hidden unit to have unit norm.For instance, in a Dense layer the weight matrix
              has shape [inputDim, outputDim],
              set axis to 0 to constrain each weight vector
              of length [inputDim,].
              In a Conv2D layer with dataFormat="channels_last",
              the weight tensor has shape
              [rows, cols, inputDepth, outputDepth], setaxisto[0, 1, 2]to constrain the weights of each filter tensor of size[rows, cols, inputDepth]`.Initializers are used in Layers
      to establish the starting the values of weights, biases, kernels, 
      etc.Initializer that generates values initialized to some constant.Glorot normal initializer, also called Xavier normal initializer.
It draws samples from a truncated normal distribution centered on 0
with stddev = sqrt(2 / (fan_in + fan_out))
where fan_in is the number of input units in the weight tensor
and fan_out is the number of output units in the weight tensor.Reference:
Glorot & Bengio, AISTATS 2010
http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdfGlorot uniform initializer, also called Xavier uniform initializer.
It draws samples from a uniform distribution within [-limit, limit]
where limit is sqrt(6 / (fan_in + fan_out))
where fan_in is the number of input units in the weight tensor
and fan_out is the number of output units in the weight tensorReference:
Glorot & Bengio, AISTATS 2010
http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf.It draws samples from a truncated normal distribution centered on 0
with stddev = sqrt(2 / fanIn)
where fanIn is the number of input units in the weight tensor.It draws samples from a uniform distribution within [-limit, limit]
where limit is sqrt(6 / fan_in)
where fanIn is the number of input units in the weight tensor.Initializer that generates the identity matrix.
Only use for square 2D matrices.It draws samples from a truncated normal distribution centered on 0
with stddev = sqrt(1 / fanIn)
where fanIn is the number of input units in the weight tensor.References:
Self-Normalizing Neural Networks
Efficient BackpropIt draws samples from a uniform distribution in the interval
[-limit, limit] with limit = sqrt(3 / fanIn),
where fanIn is the number of input units in the weight tensor.Initializer that generates tensors initialized to 1.Initializer that generates a random orthogonal matrix.Initializer that generates random values initialized to a normal
distribution.Initializer that generates random values initialized to a uniform
distribution.Values will be distributed uniformly between the configured minval and
maxval.Initializer that generates random values initialized to a truncated normal.
distribution.These values are similar to values from a RandomNormal except that values
more than two standard deviations from the mean are discarded and re-drawn.
This is the recommended initializer for neural network weights and filters.Initializer capable of adapting its scale to the shape of weights.
With distribution=NORMAL, samples are drawn from a truncated normal
distribution centered on zero, with stddev = sqrt(scale / n) where n is:Initializer that generates tensors initialized to 0.Regularizers can be attached to various components
      of a Layer to add a 'scoring' function to help drive weights, or 
      other trainable values, away from excessively large values.  They're
      typically used to promote a notion that a 'simpler' model is better
      than a complicated model, assuming equal performance.Adds a term to the loss to penalize large weights:
loss += sum(l1 * abs(x))Regularizer for L1 and L2 regularization.Adds a term to the loss to penalize large weights:
loss += sum(l1 * abs(x)) + sum(l2 * x^2)Adds a term to the loss to penalize large weights:
loss += sum(l2 * x^2)TensorFlow.js Data provides simple APIs to load and parse data 
      from disk or over the web in a variety of formats, and to prepare 
      that data for use in machine learning models (e.g. via operations 
      like filter, map, shuffle, and batch).
        Create a Dataset from an array of elements.Create a Dataset from an array of objects:Create a Dataset from an array of numbers:Create a CSVDataset by reading and decoding CSV file(s) from provided URL
or local path if it's in Node environment.Note: If isLabel in columnConfigs is true for at least one column, the
element in returned CSVDataset will be an object of
{xs:features, ys:labels}: xs is a dict of features key/value pairs, ys
is a dict of labels key/value pairs. If no column is marked as label,
returns a dict of features only.required If value in this column is required. If set to true, throw
              an error when it finds an empty value.dtype Data type of this column. Could be int32, float32, bool, or
              string.default Default value of this column.isLabel Whether this column is label instead of features. If isLabel is
              true for at least one column, the element in returned CSVDataset will
              be an object of {xs: features, ys: labels}: xs is a dict of features
              key/value pairs, ys is a dict of labels key/value pairs. If no column is
              marked as label, returns a dict of features only.Create a Dataset that produces each element from provided JavaScript
generator, which is a function*
(https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators#Generator_functions),
or a function that returns an
iterator
(https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators#Generator_functions).The returned iterator should have .next() function that returns element in
format of {value: TensorContainer, done:boolean}.Example of creating a dataset from an iterator factory:Example of creating a dataset from a generator:Create an iterator that generate frequency-domain spectrogram Tensors from
microphone audio stream with browser's native FFT. This API only works in
browser environment when the device has microphone.Note: this code snippet only works when the device has a microphone. It will
request permission to open the microphone when running.Create an iterator that generate Tensors from webcam video stream. This API
only works in Browser environment when the device has webcam.Note: this code snippet only works when the device has a webcam. It will
request permission to open the webcam when running.Create a Dataset by zipping together an array, dict, or nested
structure of Datasets (and perhaps additional constants).
The underlying datasets must provide elements in a consistent order such that
they correspond.The number of elements in the resulting dataset is the same as the size of
the smallest dataset in datasets.The nested structure of the datasets argument determines the
structure of elements in the resulting iterator.Note this means that, given an array of two datasets that produce dict
elements, the result is a dataset that produces elements that are arrays
of two dicts:Represents a potentially large collection of delimited text records.The produced TensorContainers each contain one key-value pair for
every column of the table.  When a field is empty in the incoming data, the
resulting value is undefined, or throw error if it is required.  Values
that can be parsed as numbers are emitted as type number, other values
are parsed as string.Returns column names of the csv dataset. If configuredColumnsOnly is
true, return column names in columnConfigs. If configuredColumnsOnly is
false and columnNames is provided, columnNames. If
configuredColumnsOnly is false and columnNames is not provided, return
all column names parsed from the csv file. For example usage please go to
tf.data.csv().Represents a potentially large list of independent data elements (typically
'samples' or 'examples').A 'data example' may be a primitive, an array, a map from string keys to
values, or any nested structure of these.A Dataset represents an ordered collection of elements, together with a
chain of transformations to be performed on those elements. Each
transformation is a method of Dataset that returns another Dataset, so
these may be chained, e.g.
const processedDataset = rawDataset.filter(...).map(...).batch(...).Data loading and transformation is done in a lazy, streaming fashion.  The
dataset may be iterated over multiple times; each iteration starts the data
loading anew and recapitulates the transformations.A Dataset is typically processed as a stream of unbatched examples --i.e.,
its transformations are applied one example at a time. Batching produces a
new Dataset where each element is a batch. Batching should usually come
last in a pipeline, because data transformations are easier to express on a
per-example basis than on a per-batch basis.The following code examples are calling await dataset.forEachAsync(...) to
iterate once over the entire dataset in order to print out the data.It is assumed that each of the incoming dataset elements has the same
structure-- i.e. the same set of keys at each location in an object
hierarchy.  For each key, the resulting Dataset provides a batched
element collecting all of the incoming values for that key.Incoming primitives are grouped into a 1-D Tensor.
Incoming Tensors are grouped into a new Tensor where the 0'th axis is
the batch dimension.
Incoming arrays are converted to Tensor and then batched.
A nested array is interpreted as an n-D Tensor, so the batched result
has n+1 dimensions.
An array that cannot be converted to Tensor produces an error.If an array should not be batched as a unit, it should first be converted
to an object with integer keys.Filters this dataset according to predicate.Apply a function to every element of the dataset.After the function is applied to a dataset element, any Tensors contained
within that element are disposed.Maps this dataset through a 1-to-1 transform.Maps this dataset through an async 1-to-1 transform.Creates a Dataset that prefetches elements from this dataset.NOTE: If this dataset is a function of global state (e.g. a random number
generator), then different repetitions may produce different elements.Creates a Dataset that skips count initial elements from this dataset.Pseudorandomly shuffles the elements of this dataset. This is done in a
streaming manner, by sampling from a given number of prefetched elements.Creates a Dataset with at most count initial elements from this
dataset.Collect all elements of this dataset into an array.Obviously this will succeed only for small datasets that fit in memory.
Useful for testing and generally should be avoided if possible.tfjs-vis is a companion library for TensorFlow.js that provides 
      in-browser visualization capabilities for training and understanding 
      models. API docs for tfjs-vis are available here
Asserts that the expression is true. Otherwise throws an error with the
provided message.Creates a new array with randomized indicies to a given quantity.Decodes the provided bytes into a string using the provided encoding scheme.Encodes the provided string into bytes using the provided encoding scheme.Returns a platform-specific implementation of
fetch.If fetch is defined on the global object (window, process, etc.),
tf.util.fetch returns that function.If not, tf.util.fetch returns a platform-specific solution.Returns the current high-resolution time in milliseconds relative to an
arbitrary time in the past. It works across different platforms (node.js,
browsers).Shuffles the array in-place using Fisher-Yates algorithm.Shuffles two arrays in-place the same way using Fisher-Yates algorithm.Returns the size (number of elements) of the tensor given its shape.Creates a tf.Tensor from an image.Creates a tf.Tensor from an image in async way.This API is the async version of fromPixels. The API will first
check |WRAP_TO_IMAGEBITMAP| flag, and try to wrap the input to
imageBitmap if the flag is set to true.Draws a tf.Tensor of pixel values to a byte array or optionally a
canvas.When the dtype of the input is 'float32', we assume values in the range
[0-1]. Otherwise, when input is 'int32', we assume values in the range
[0-255].Returns a promise that resolves when the canvas has been drawn to.Gets the current backend. If no backends have been initialized, this will
attempt to initialize the best backend. Will throw an error if the highest
priority backend has async initialization, in which case, you should call
'await tf.ready()' before running other code.Returns the current backend name (cpu, webgl, etc). The backend is
responsible for creating tensors and executing operations on those tensors.Returns a promise that resolves when the currently selected backend (or the
highest priority one) has initialized. Await this promise when you are using
a backend that has async initialization.Registers a global backend. The registration should happen when importing
a module file (e.g. when importing backend_webgl.ts), and is used for
modular builds (e.g. custom tfjs bundle with only webgl support).Removes a backend and the registered factory.Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and
executing operations on those tensors. Returns a promise that resolves
to a boolean if the backend initialization was successful.Note this disposes the current backend, if any, as well as any tensors
associated with it. A new backend is initialized, even if it is of the
same type as the previous one.yTrue and yPred can have 0-1 values. Example:yTrue and yPred can also have floating-number values between 0 and 1, in
which case the values will be thresholded at 0.5 to yield 0-1 values (i.e.,
a value >= 0.5 and <= 1.0 is interpreted as 1.
)
Example:Categorical crossentropy between an output tensor and a target tensor.Loss or metric function: Cosine proximity.Mathematically, cosine proximity is defined as:
-sum(l2Normalize(yTrue) * l2Normalize(yPred)),
wherein l2Normalize() normalizes the L2 norm of the input to 1 and *
represents element-wise multiplication.Loss or metric function: Mean absolute error.Mathematically, mean absolute error is defined as:
mean(abs(yPred - yTrue)),
wherein the mean is applied over feature dimensions.Loss or metric function: Mean absolute percentage error.Loss or metric function: Mean squared error.Computes the precision of the predictions with respect to the labels.Computes the recall of the predictions with respect to the labels.Factory function for a Callback that stops training when a monitored
quantity has stopped improving.Early stopping is a type of regularization, and protects model against
overfitting.The following example based on fake data illustrates how this callback
can be used during tf.LayersModel.fit():If specified, training will be stopped if the model doesn't show
              improvement over the baseline.######
Original file ‎(SVG file, nominally 115 × 123 pixels, file size: 2 KB)
Vectorized on  This W3C-unspecified vector image was created with Inkscape ..
Click on a date/time to view the file as it appeared at that time.
The following page uses this file:
The following other wikis use this file:
This file contains additional information such as Exif metadata which may have been added by the digital camera, scanner, or software program used to create or digitize it. If the file has been modified from its original state, some details such as the timestamp may not fully reflect those of the original file. The timestamp is only as accurate as the clock in the camera, and it may be completely wrong.